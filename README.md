# Speech and Facial Emotion Detection

![GitHub repo size](https://img.shields.io/github/repo-size/Shuaib21803/Speech-and-Facial-Emotion-Detection-)
![GitHub contributors](https://img.shields.io/github/contributors/Shuaib21803/Speech-and-Facial-Emotion-Detection-)
![GitHub forks](https://img.shields.io/github/forks/Shuaib21803/Speech-and-Facial-Emotion-Detection-)

## Table of Contents
- [Introduction](#introduction)
- [Usage](#usage)

## Introduction

A simple emotion detection model developed using Machine Learning which detects facial emotions as well as speech emotions.

## Usage
To use our emotion detection model:
  1. Simply clone or download and unzip the repository.
  2. Install tensorflow, cv2, librosa, soundfile and other modules as required in your system using pip. (You can cross-check the modules used in the 
     respective .ipynb files and install required ones)
  3. Run the gui.py file.
  4. Choose Speech Detection or Facial Detection.
  5. Upload the audio file or image to detect an emotion.
  6. Click on the Detect button.
